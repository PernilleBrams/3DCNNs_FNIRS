---
title: "H2 testing and visualizations for LOSO-CV"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load in the relevant packages 
```{r}
library(pacman)
p_load(tidyverse,dplyr,wesanderson, lme4, lmerTest, RColorBrewer)
```

## Hypothesis 1: Validation 
### Visualization of LOSO-CV models  
```{r}
# Loading in the data
df <- read.csv("Performance metrices LOO.csv", sep = ";") 

# Cleaning the data and select the relevant variables
df <- df %>% 
  mutate(TestErrorRate = sub(",",".",df$Test_error),
         TestAccuracy = sub(",", ".", df$Test_acc),
         TestLoss = sub(",",".", df$Test_loss),
         F1_score = sub(",",".", df$f1_score)) %>% select(-c(Test_error,Test_acc,Test_loss,f1_score))

# Converting the values to the appropriate classes
df$Participant_ID <- as.factor(df$Participant_ID)
df$TestErrorRate <- as.numeric(df$TestErrorRate)
df$TestAccuracy <- as.numeric(df$TestAccuracy)*100
df$TestLoss <- as.numeric(df$TestLoss)
df$F1_score <- as.numeric(df$F1_score)

# Scaling the data
df$scaled_testacc <- scale(df$TestAccuracy)
df <- df %>% filter(scaled_testacc > -3 & scaled_testacc < 3)


# -- PLOTS --

# TEST ACCURACIES
df %>%  ggplot(aes(x=as.factor(Participant_ID), y=TestAccuracy, fill = TestAccuracy, label = TestAccuracy)) +
  geom_bar(stat="identity") + 
  theme_minimal() + 
  ylim(c(0,100)) + 
  labs(title = "Test accuracies for LOSO-CV", 
       subtitle = "Black line set at 70% (BCI threshold)Orange line set at 50% (chance level)", 
       caption = "Klara Krøyer / Pernille Brams") + 
  geom_hline(yintercept=70, color = "black") + 
  geom_hline(yintercept=50, color = "orange") + 
  xlab("Participant ID")+ 
  ylab("Test Accuracy in %") + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  geom_text(size = 3, position = position_stack(vjust = 1.05)) +
  theme(plot.title = element_text(face = "bold")) + 
  scale_fill_gradientn(colors = alpha(c(brewer.pal(11, "GnBu")), alpha = .9))


# F1 SCORE
df %>%  ggplot(aes(x=as.factor(Participant_ID), y=F1_score, fill = F1_score, label = F1_score)) +
  geom_bar(stat="identity")+
  theme_minimal() + 
  ylim(c(0,1)) + 
  labs(title = "f1-scores for LOSO-CV", 
       subtitle = "Orange line set at 0.5 (A perfect f1-score corresponds to value of 1)", 
       caption = "Klara Krøyer / Pernille Brams") + 
  geom_hline(yintercept=.5, color = "orange") + 
  xlab("Participant ID")+ 
  ylab("f1-score") + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  geom_text(size = 3, position = position_stack(vjust = 1.05)) +
  theme(plot.title = element_text(face = "bold")) + 
  scale_fill_gradientn(colors = alpha(c(brewer.pal(11, "GnBu")), alpha = .9))
```


## Hypothesis 2: Transfer learning

### Visualization of models using transferlearning (pretrained on LOSO-CV) and models trained one single-subject data 
```{r}
# Loading in the data
dftl <- readxl::read_xlsx("LOO_results_r.xlsx")

dftl$`Test acc`
meansd_df <- dftl %>% 
  group_by(ID,Mode) %>% 
  summarise(mean = mean(`Test acc`), 
            sd = sd(`Test acc`), 
            mean_f1 = mean(f1score), 
            sd_f1 = sd(f1score))

# -- PLOTS --

# Specifying colors
my_colors <- RColorBrewer::brewer.pal(8, "GnBu")[3:7]



# F1 SCORES 
meansd_df %>%  ggplot(aes(x=as.factor(ID), y=mean_f1, fill = Mode)) +
  geom_bar(stat="identity", position = "dodge",color = "darkblue", size = .2 ) + 
  theme_minimal() + ylim(c(0,1)) +
  labs(title = "Mean f1-scores across folds for single-person-models for each mode", 
       subtitle = "Black line set at 70% (BCI threshold) (Note: Plot shows f1-score, not test acc.)", 
       caption = "Klara Krøyer / Pernille Brams") + ylab("f1-score") + scale_x_discrete(guide = guide_axis(angle = 90)) +
  theme(plot.title = element_text(face = "bold")) + 
  scale_fill_brewer(palette = "GnBu") +
  geom_errorbar(aes(ymin=mean_f1-sd_f1, ymax=mean_f1+sd_f1, width=.2),
                 position=position_dodge(.9), alpha = .6)+ 
  geom_hline(yintercept=0.7, color = "black") + 
  xlab("Participant ID")


# F1 SCORES - Four separate plots for each approach
meansd_df %>%  ggplot(aes(x=as.factor(ID), y=mean_f1, fill = Mode)) +
  geom_bar(stat="identity", position = "dodge")+theme_minimal() + 
  ylim(c(0,1)) + 
  labs(title = "Mean f1-scores across folds for single-person-models for each mode", 
                      subtitle = "Black line set at 70% (BCI threshold) (Note: Plot shows f1-score)", 
                      caption = "Klara Krøyer / Pernille Brams") +
  geom_hline(yintercept=0.7, color = "black") + 
  xlab("Participant ID")+ 
  ylab("f1 score") + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  theme(plot.title = element_text(face = "bold")) + 
  scale_fill_manual(values = my_colors) +
  geom_errorbar(aes(ymin=mean_f1-sd_f1, ymax=mean_f1+sd_f1), width=.2,
                 position=position_dodge(.9))+facet_wrap(~Mode)


# TEST ACCURACIES
meansd_df %>%  ggplot(aes(x=as.factor(ID), y=mean*100, fill = Mode)) +
  geom_bar(stat="identity", position = "dodge") +
  theme_minimal() + 
  ylim(c(0,100)) + 
  labs(title = "Mean test accuracies across folds for single-person-models for each mode", 
       subtitle = "Black line set at 70% (BCI threshold)", 
       caption = "Klara Krøyer / Pernille Brams") + 
  ylab("Test Accuracy in %") + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  theme(plot.title = element_text(face = "bold")) + 
  scale_fill_brewer(palette = "GnBu")
  geom_errorbar(aes(ymin=mean*100-sd*100, ymax=mean*100+sd*100), width=.2,
                 position=position_dodge(.9)) + 
  geom_hline(yintercept=70, color = "black") + 
  xlab("Participant ID")




```

### Testing H2: A linear mixed effects 
https://stats.stackexchange.com/questions/31569/questions-about-how-random-effects-are-specified-in-lmer


```{r}
# Libraries
pacman::p_load(MuMIn, emmeans,lattice) 
 
```

```{r}
# Loading the full dataset
full_df <- readxl::read_xlsx("LOO_results_r.xlsx") %>% rename(Test_acc = `Test acc`, Test_loss = `Test loss`) 

full_df$Mode <- as.factor(full_df$Mode)


# Set Mode "Scratch" as the first level to make it the intercept
levels(full_df$Mode)
full_df$Mode = relevel(full_df$Mode, ref = "Scratch")

# Model
m1 = lmer(f1score ~ Mode + (1|ID),full_df)
summary(m1)

# Adjusted r-squared
MuMIn::r.squaredGLMM(m1)

# Checking assumptions with diagnostic plots
plot(m1)
qqnorm(resid(m1))

# Pairwise
emm_r <- emmeans(m1, pairwise ~ Mode)
emm_r

```

### POST HOC: Comparison of means and SDs
```{r}
# Summarize means and SDs for each mode
full_df %>% group_by(Mode) %>% summarise(mean = mean(f1score),
                                         sd = sd(f1score))
full_df %>% group_by(Mode) %>% summarise(mean = mean(Test_acc),
                                         sd = sd(Test_acc))

# Getting data for the different modes
mode_m1 <- meansd_df %>% select(Mode,mean_f1)
scratch_m1 <- mode_m1 %>% filter(Mode == "Scratch")
FE_m <- mode_m1 %>% filter(Mode == "FE")
FT_m <- mode_m1 %>% filter(Mode == "FT")
FTA_m <- mode_m1 %>% filter(Mode == "FTA")

# Assumptions of normality passed
qqnorm(scratch_m1$mean_f1, pch = 1, frame = FALSE)
qqline(scratch_m1$mean_f1, col = "steelblue", lwd = 2)

qqnorm(FE_m$mean_f1, pch = 1, frame = FALSE)
qqline(FE_m$mean_f1, col = "steelblue", lwd = 2)

qqnorm(FT_m$mean_f1, pch = 1, frame = FALSE)
qqline(FT_m$mean_f1, col = "steelblue", lwd = 2)

qqnorm(FTA_m$mean_f1, pch = 1, frame = FALSE)
qqline(FTA_m$mean_f1, col = "steelblue", lwd = 2)

# F-tests
var.test(scratch_m1$mean_f1, FE_m$mean_f1, ratio = 1,
         alternative = c("greater"),
         conf.level = 0.95)

var.test(scratch_m1$mean_f1, FT_m$mean_f1, ratio = 1,
         alternative = c("greater"),
         conf.level = 0.95)

var.test(scratch_m1$mean_f1, FTA_m$mean_f1, ratio = 1,
         alternative = c("greater"),
         conf.level = 0.95)
```









